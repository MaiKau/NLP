{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd3c09e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import distance\n",
    "import jieba\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import synonyms\n",
    "from gensim.models import *\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "cnxn = pyodbc.connect(r'Driver=SQL Server;Server=LAPTOP-VFEIS9GU;Database=DIET;Trusted_Connection=yes;') #連線DB\n",
    "cursor = cnxn.cursor()\n",
    "cursor.execute(\"SELECT Name FROM MOS\")\n",
    "\n",
    "corpus_data = []\n",
    "result = cursor.fetchall()  #讀DB\n",
    "for row in result:\n",
    "    corpus_data.append(row)\n",
    "\n",
    "#字串處理\n",
    "corpus_data=str(corpus_data).replace('(','').replace(')','').replace(',, ',',').replace('[','').replace(']','').replace(\"'\",\"\").replace(' ','')  \n",
    "corpus_data=corpus_data.split(',')\n",
    "corpus_data=list(corpus_data)\n",
    "k=1\n",
    "for i in range(len(corpus_data)):\n",
    "    if i%2==1:\n",
    "        del corpus_data[k]\n",
    "        k=k+1\n",
    "\n",
    "path= '7_Algorithm.txt'                   #寫入w2v需要的txt作為語料庫\n",
    "\n",
    "with open('7_Algorithm.txt','a+',encoding='UTF-8') as test: #清空\n",
    "    test.truncate(0)\n",
    "    \n",
    "for write in corpus_data:                                    #寫入\n",
    "    f = open(path, 'a',encoding='UTF-8')\n",
    "    f.write(write)\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "train_data = word2vec.LineSentence('7_Algorithm.txt')\n",
    "\n",
    "cnxn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b73de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Levenshtein(keyword):\n",
    "    def edit_distance(corpus_data, keyword):\n",
    "        return distance.levenshtein(corpus_data, keyword)\n",
    "    i=0\n",
    "    for i in range(10):\n",
    "        i=i+1\n",
    "        results = list(filter(lambda x: edit_distance(x, keyword) <= i, corpus_data))\n",
    "        if(len(results)>9):\n",
    "#             print(\"step\",i,results)\n",
    "            break\n",
    "        else:\n",
    "#             print(\"step\",i,\"未達top10\")\n",
    "            continue\n",
    "\n",
    "    long=len(results)           #create等長list\n",
    "    Similarity=['-']*long           \n",
    "\n",
    "    #df sort\n",
    "    dict_df1={\n",
    "             \"Similarity\":Similarity,   \n",
    "             \"Name\":results\n",
    "            }\n",
    "    data1=DataFrame(dict_df1)\n",
    "    sult1=data1\n",
    "    return(sult1)\n",
    "\n",
    "    \n",
    "def BM25(keyword):\n",
    "    tokenized_corpus = [list(jieba.cut(doc)) for doc in corpus_data]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    tokenized_query = list(jieba.cut(keyword))\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "    top10 = bm25.get_top_n(tokenized_query,corpus_data,n=10)\n",
    "\n",
    "    # print(\"斷詞結果:\",tokenized_corpus)\n",
    "\n",
    "    list_doc_scores = list(doc_scores)\n",
    "    list_corpus = list(corpus_data)\n",
    "\n",
    "    #df sort\n",
    "    dict_df2={\"Similarity\":list_doc_scores,\n",
    "             \"Name\":list_corpus\n",
    "            }\n",
    "    data2=DataFrame(dict_df2)\n",
    "    sult2=data2.sort_values(by=['Similarity'],ascending=False)\n",
    "    sult2 = sult2.reset_index(drop=True) #reset df index  \n",
    "    return(sult2)\n",
    "\n",
    "\n",
    "def jaccard(keyword):\n",
    "    def jaccard_similarity(corpus_data,keyword):\n",
    "        def add_space(s):\n",
    "            return ' '.join(list(s))\n",
    "\n",
    "        # 將字中間加入空格\n",
    "        corpus_data, keyword = add_space(corpus_data), add_space(keyword)\n",
    "        # 轉化為TF矩陣\n",
    "        cv = CountVectorizer(tokenizer=lambda s: s.split())\n",
    "        corpus = [corpus_data, keyword]\n",
    "        vectors = cv.fit_transform(corpus).toarray()\n",
    "        # 求交集\n",
    "        numerator = np.sum(np.min(vectors, axis=0))\n",
    "        # 求聯集\n",
    "        denominator = np.sum(np.max(vectors, axis=0))\n",
    "        # 計算傑卡德係數\n",
    "        return 1.0 * numerator / denominator\n",
    "\n",
    "    list_name=[]\n",
    "    list_similarity=[]\n",
    "    i=-1\n",
    "    for abc in corpus_data:\n",
    "        i=i+1\n",
    "        Similarity=jaccard_similarity(corpus_data[i], keyword)\n",
    "        list_name.append(corpus_data[i])\n",
    "        list_similarity.append(Similarity)\n",
    "\n",
    "    #df sort\n",
    "    dict_df3={\"Similarity\":list_similarity,\n",
    "              \"Name\":list_name\n",
    "               }\n",
    "    data3=DataFrame(dict_df3)\n",
    "    sult3=data3.sort_values(by=['Similarity'],ascending=False)\n",
    "    sult3 = sult3.reset_index(drop=True) #reset df index\n",
    "    return(sult3)\n",
    "\n",
    "\n",
    "def TFIDF(keyword):\n",
    "    class TF_IDF_Model(object):\n",
    "        def __init__(self, corpus_data):\n",
    "            self.corpus_data = corpus_data\n",
    "            self.documents_number = len(corpus_data)\n",
    "            self.tf = []\n",
    "            self.idf = {}\n",
    "            self.init()\n",
    "\n",
    "        def init(self):\n",
    "            df = {}\n",
    "            for document in self.corpus_data:\n",
    "                temp = {}\n",
    "                for word in document:\n",
    "                    temp[word] = temp.get(word, 0) + 1/len(document)\n",
    "                self.tf.append(temp)\n",
    "                for key in temp.keys():\n",
    "                    df[key] = df.get(key, 0) + 1\n",
    "            for key, value in df.items():\n",
    "                self.idf[key] = np.log(self.documents_number / (value + 1))\n",
    "\n",
    "        def get_score(self, index, keyword):\n",
    "            score = 0.0\n",
    "            for q in keyword:\n",
    "                if q not in self.tf[index]:\n",
    "                    continue\n",
    "                score += self.tf[index][q] * self.idf[q]\n",
    "            return score\n",
    "\n",
    "        def get_documents_score(self, keyword):\n",
    "            score_list = []\n",
    "            for i in range(self.documents_number):\n",
    "                score_list.append(self.get_score(i, keyword))\n",
    "            return score_list\n",
    "        \n",
    "    tf_idf_model = TF_IDF_Model(corpus_data)\n",
    "    scores = tf_idf_model.get_documents_score(keyword)\n",
    "\n",
    "    #df sort\n",
    "    dict_df4={\"Similarity\":scores,\n",
    "             \"Name\":corpus_data\n",
    "            }\n",
    "    data4=DataFrame(dict_df4)\n",
    "    sult4=data4.sort_values(by=['Similarity'],ascending=False)\n",
    "    sult4 = sult4.reset_index(drop=True) #reset df index\n",
    "    return(sult4)\n",
    "\n",
    "\n",
    "def Synonyms(keyword):\n",
    "    Similarity_list=[]\n",
    "    name_list=[]\n",
    "\n",
    "    i=-1\n",
    "    for abc in corpus_data:\n",
    "        i=i+1\n",
    "        r = synonyms.compare(corpus_data[i], keyword, seg=False)\n",
    "        Similarity_list.append(r)\n",
    "        name_list.append(corpus_data[i])\n",
    "\n",
    "    dict_df5={\"Similarity\":Similarity_list,\n",
    "             \"Name\":name_list\n",
    "            }\n",
    "    data5=DataFrame(dict_df5)\n",
    "    sult5=data5.sort_values(by=['Similarity'],ascending=False)\n",
    "    sult5 = sult5.reset_index(drop=True) #reset df index\n",
    "    return(sult5)\n",
    "\n",
    "\n",
    "def word2vec(keyword):\n",
    "    seed = 666\n",
    "    sg = 0\n",
    "    window_size = 1\n",
    "    vector_size = 20\n",
    "    min_count = 1\n",
    "    workers = 5\n",
    "    epochs = 200\n",
    "    batch_words = 10000\n",
    "    \n",
    "    # Train\n",
    "#     train_data = word2vec.LineSentence('7_Algorithm.txt')\n",
    "\n",
    "    model = fasttext.FastText(\n",
    "        train_data,\n",
    "        min_count=min_count,\n",
    "        vector_size=vector_size,\n",
    "        workers=workers,\n",
    "        epochs=epochs,\n",
    "        window=window_size,\n",
    "        sg=sg,\n",
    "        seed=seed,\n",
    "        batch_words=batch_words,\n",
    "    )\n",
    "    model.save('fasttext.model')\n",
    "\n",
    "\n",
    "    # 加載已訓練好的模型\n",
    "    model = Word2Vec.load('fasttext.model')\n",
    "\n",
    "    # 加載已訓練好的模型\n",
    "    model = Word2Vec.load('fasttext.model')\n",
    "\n",
    "    # 計算相關詞\n",
    "    res2 = model.wv.most_similar(keyword, topn=10)\n",
    "\n",
    "    abc=str(res2).split(',')\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "\n",
    "    i=-1\n",
    "    for ggg in abc:\n",
    "        i=i+1\n",
    "        if i%2 ==0:\n",
    "            list1.append(abc[i])\n",
    "        else:\n",
    "            list2.append(abc[i])\n",
    "\n",
    "    dict_df6={\n",
    "             \"Similarity\":list2,\n",
    "             \"Name\":list1\n",
    "\n",
    "            }\n",
    "    data6=DataFrame(dict_df6)\n",
    "    sult6=data6.sort_values(by=['Similarity'],ascending=False)\n",
    "    sult6['Name'] = sult6['Name'].str.replace(r'[^\\w\\s]+', '')\n",
    "    sult6['Similarity'] = sult6['Similarity'].str.replace(')', '')\n",
    "    sult6 = sult6.reset_index(drop=True) #reset df index\n",
    "    return(sult6)\n",
    "\n",
    "\n",
    "def sbert(keywork):\n",
    "    model_name='paraphrase-multilingual-mpnet-base-v2' #sbert官方預訓練模型 https://www.sbert.net/docs/pretrained_models.html \n",
    "\n",
    "    model = SentenceTransformer(model_name) #load pre-model\n",
    "    sentence_vecs = model.encode(corpus_data) #向量化\n",
    "    query_vecs = model.encode(keywork)        #向量化\n",
    "\n",
    "    similarity_list=[]\n",
    "    Name_list=corpus_data\n",
    "\n",
    "    i=-1\n",
    "    for cde in sentence_vecs:\n",
    "        i=i+1\n",
    "        result=cosine_similarity( [query_vecs[0]], [sentence_vecs[i]] )\n",
    "        result=result.tolist()\n",
    "        similarity_list.append(result)\n",
    "\n",
    "    dict_df7={\n",
    "             \"Similarity\":similarity_list,         \n",
    "             \"Name\":Name_list\n",
    "            }\n",
    "\n",
    "    data7=DataFrame(dict_df7)\n",
    "    sult7=data7.sort_values(by=['Similarity'],ascending=False) #sort\n",
    "    sult7 = sult7.reset_index(drop=True) #reset df index\n",
    "    return(sult7)\n",
    "\n",
    "def Algorithm7_Vote_Top1(keyword):\n",
    "    df_top1 = pd.concat([Levenshtein(keyword)[0:1],jaccard(keyword)[0:1],BM25(keyword)[0:1],TFIDF(keyword)[0:1],Synonyms(keyword)[0:1],word2vec(keyword)[0:1],sbert([keyword])[0:1]],axis=0)\n",
    "    freq_top1 = df_top1.groupby(['Name']).count() \n",
    "    freq_top1 = freq_top1.sort_values(by=['Similarity'],ascending=False) #sort\n",
    "    return(freq_top1)\n",
    "\n",
    "def Algorithm7_Vote_Top10(keyword):\n",
    "    df_top10 = pd.concat([Levenshtein(keyword)[0:10],jaccard(keyword)[0:10],BM25(keyword)[0:10],TFIDF(keyword)[0:10],Synonyms(keyword)[0:10],word2vec(keyword)[0:10],sbert([keyword])[0:10]],axis=0)\n",
    "    freq_top10 = df_top10.groupby(['Name']).count()\n",
    "    freq_top10 = freq_top10.sort_values(by=['Similarity'],ascending=False) #sort\n",
    "    return(freq_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63a77827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>海洋珍珠堡</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>燒肉珍珠堡牛</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>米斯球</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>薑燒珍珠堡</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Similarity\n",
       "Name              \n",
       "海洋珍珠堡            4\n",
       "燒肉珍珠堡牛           1\n",
       "米斯球              1\n",
       "薑燒珍珠堡            1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "Algorithm7_Vote_Top1(\"珍珠堡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60002d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>杏鮑菇珍珠堡</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>海洋珍珠堡</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>藜麥海洋珍珠堡</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>薑燒珍珠堡</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>蜜芋紅豆珍珠堡</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>燒肉珍珠堡牛</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>藜麥薑燒珍珠堡</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOS洋蔥圈</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>藜麥杏鮑菇珍珠堡</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>薯條S</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>薯條L</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>米斯球</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>御品白燒鰻珍珠堡</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>北海道可樂餅</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>咕咕雞堡</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>冰紅茶</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>元氣牛肉珍珠堡牛</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>薑燒珍珠堡</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>燒肉珍珠堡牛</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>澳式黑咖啡熱M</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>杏鮑菇珍珠堡</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>摩斯純淨水</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>摩斯純淨天然水</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>摩斯熱紅茶</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>雪碧</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Similarity\n",
       "Name                \n",
       "杏鮑菇珍珠堡            12\n",
       "海洋珍珠堡             12\n",
       "藜麥海洋珍珠堡            9\n",
       "薑燒珍珠堡              6\n",
       "蜜芋紅豆珍珠堡            5\n",
       "燒肉珍珠堡牛             5\n",
       "藜麥薑燒珍珠堡            3\n",
       " MOS洋蔥圈            1\n",
       "藜麥杏鮑菇珍珠堡           1\n",
       "薯條S                1\n",
       "薯條L                1\n",
       "米斯球                1\n",
       "御品白燒鰻珍珠堡           1\n",
       " 北海道可樂餅            1\n",
       "咕咕雞堡               1\n",
       "冰紅茶                1\n",
       "元氣牛肉珍珠堡牛           1\n",
       " 薑燒珍珠堡             1\n",
       " 燒肉珍珠堡牛            1\n",
       " 澳式黑咖啡熱M           1\n",
       " 杏鮑菇珍珠堡            1\n",
       " 摩斯純淨水             1\n",
       " 摩斯純淨天然水           1\n",
       " 摩斯熱紅茶             1\n",
       "雪碧                 1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "Algorithm7_Vote_Top10(\"珍珠堡\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
